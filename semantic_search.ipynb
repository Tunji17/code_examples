{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q sentencepiece torch transformers numpy pandas protobuf scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 0.4828,  0.3504,  0.0829,  ...,  0.0499, -0.1595, -0.3722],\n",
      "        [ 0.2384, -0.3978, -0.0407,  ..., -1.2387, -0.1273,  0.3967],\n",
      "        [ 0.4384,  0.6839,  0.1998,  ..., -0.1153, -0.3081, -0.4717],\n",
      "        [ 0.4972,  0.7983,  0.0944,  ..., -0.1175, -0.4632,  0.5812],\n",
      "        [ 0.0112, -0.5605, -0.3236,  ..., -0.0455, -0.0269,  0.3353],\n",
      "        [-0.1307, -0.1798, -0.2947,  ...,  1.0156,  0.3974, -0.4707]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def get_embedding(tokenizer, model, data):\n",
    "\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(data, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling. In this case, max pooling.\n",
    "    return mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "\n",
    "# dataset we want embeddings for\n",
    "data = pd.DataFrame({\n",
    "    'title': [\n",
    "        'Infringement of Copyright: Legal Proceedings and Remedies',\n",
    "        'Harnessing Hugging Face: Revolutionizing NLP with Transformers Library',\n",
    "        'Patent Breach Litigation: Analysis and Enforcement Strategies',\n",
    "        'Quantum Computing Unleashed: Breaking Down Complexities',\n",
    "        'Microbiome Mysteries: Unlocking Gut Health Secrets',\n",
    "        'Solar Power Surge: Illuminating Renewable Energys Future'],\n",
    "    'content': [\n",
    "        'This document addresses the legal framework surrounding copyright violation, including statutory damages, injunctive relief, and defendant liabilities....',\n",
    "        'Explore how Hugging Faces Transformers library is transforming NLP. Unmatched ease-of-use, advanced models, and community-driven innovation redefine AIs future...',\n",
    "        'Detailing patent infringement cases, this brief explores judicial remedies, infringement criteria, and defense strategies in patent law...',\n",
    "        'Demystifying quantum computings complexities. Insight into qubits, quantum supremacy, and its potential to revolutionize technology....',\n",
    "        'Exploring the gut microbiomes impact on health. New research unveils links between bacteria diversity and disease prevention...',\n",
    "        'Analyzing solar energys rapid growth. Innovations in photovoltaic technology and global impact on sustainable energy shift...']\n",
    "})\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-distilroberta-base-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/paraphrase-distilroberta-base-v2')\n",
    "\n",
    "sentence_embeddings = get_embedding(tokenizer, model, data['content'].tolist())\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  Infringement of Copyright: Legal Proceedings a...   \n",
      "1  Patent Breach Litigation: Analysis and Enforce...   \n",
      "2  Harnessing Hugging Face: Revolutionizing NLP w...   \n",
      "3  Quantum Computing Unleashed: Breaking Down Com...   \n",
      "4  Solar Power Surge: Illuminating Renewable Ener...   \n",
      "\n",
      "                                             content  similarity  \n",
      "0  This document addresses the legal framework su...    0.614404  \n",
      "1  Detailing patent infringement cases, this brie...    0.503443  \n",
      "2  Explore how Hugging Faces Transformers library...    0.100846  \n",
      "3  Demystifying quantum computings complexities. ...    0.063512  \n",
      "4  Analyzing solar energys rapid growth. Innovati...    0.007385  \n"
     ]
    }
   ],
   "source": [
    "query = \"intellectual property infringement\"\n",
    "def search(query, top_n=5):\n",
    "\n",
    "    query_embeddings = get_embedding(tokenizer, model, [query])\n",
    "    similarities = cosine_similarity(query_embeddings, sentence_embeddings)\n",
    "    top_indices = np.argsort(-similarities[0])[:top_n]\n",
    "    top_results = data.iloc[top_indices].reset_index(drop=True)\n",
    "    top_results['similarity'] = similarities[0][top_indices]\n",
    "    return top_results\n",
    "results = search(query, top_n=5)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-rag-FsZTofeu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
